# Load required Librbaries:
library(kernlab)
library(readr)
library(caret)
library(caTools)
library(e1071)
library(dplyr)
library(doParallel)
setwd("C:/Users/abhik/Desktop/Work Folder/R Projects/Digit Recognition")
?read_csv()
train_data <- read_csv("mnist_train.csv", col_names = T)
test_data <- read_csv("mnist_test.csv", col_names = T)
str(train_data)
dim(train_data)
dim(test_data)
#View(train_data)
head(train_data)
train_data <- read_csv("mnist_train.csv", col_names = F)
test_data <- read_csv("mnist_test.csv", col_names = F)
train_data[1:10, 1:10]
library(tidyr)
digit1 <- matrix(train_data[1,-1], nrow = 28, ncol=28)
digit1
plot(digit1)
plot(c(digit1))
plot(c(digit1))
library(fields)
install.packages("fields")
library(fields)
image.plot(digit1)
image.plot(matrix(train_data[1,-1], nrow = 28, ncol=28)
image.plot(matrix(train_data[1,-1], nrow = 28, ncol=28))
digit1 <- matrix(train_data[1,-1], nrow = 28, ncol=28)
digit1
digit1 <- matrix(train_data[1,-1], nrow = 28, ncol=28, byrow=T)
digit1
longData <- melt(digit1)
install.packages("reshape2")
install.packages("reshape2")
library(reshape2)
library(reshape2)
dim(train_data)
dim(test_data)
renameColumns < function(df){
colnames(df) <- paste0("y", 0:(ncol(df)-1))
}
renameColumns <- function(df){
colnames(df) <- paste0("y", 0:(ncol(df)-1))
}
renameColumns(train_data)
colnames(train_data)
renameColumns <- function(df){
colnames(df) <- paste0("y", 0:(ncol(df)-1))
return(df)
}
train_data <- renameColumns(train_data)
colnames(train_data)
#View(train_data)
head(train_data)
renameColumns <- function(df){
colnames(df) <- paste0("Y", 0:(ncol(df)-1))
colnames(df)[which(names(df) == "Y0")] <- "DIGIT"
return(df)
}
train_data <- renameColumns(train_data)
colnames(train_data)
test_data <- renameColumns(test_data)
colnames(test_data)
str(train_data)
View(test_data)
head(train_data)
# Changing output variable "DIGIT" to factor type
train_data$DIGIT <- as.factor(train_data$DIGIT)
test_data$DIGIT <- as.factor(test_data$DIGIT)
# Checking missing value
sapply(train_data, function(x) sum(is.na(x))) # No missing values
# Checking missing value
sum(sapply(train_data, function(x) sum(is.na(x)))) # No missing values
sum(sapply(test_data, function(x) sum(is.na(x)))) # No missing values
sum(duplicated(train_data)) # no duplicate rows
# Sampling the data to make the computation faster
set.seed(100)
train_subset.indices = sample(1:nrow(train_data), 0.15*nrow(train_data))
train = train_data[train_subset.indices, ]
test_subset.indices = sample(1:nrow(test_data), 0.15*nrow(test_data))
test <- test_data[test_subset.indices, ]
max(train[ ,2:ncol(train)]) # max pixel value is 255, lets use this to scale data
train[ , 2:ncol(train)] <- train[ , 2:ncol(train)]/255
#test <- cbind(test_data[,1],test_data[ , 2:ncol(test_data)]/255)
test[ , 2:ncol(test)] <- test[ , 2:ncol(test)]/255
Model_linear <- ksvm(DIGIT~ ., data = train, scaled = FALSE, kernel = "vanilladot")
Model_linear <- ksvm(DIGIT~ ., data = train, scaled = FALSE, kernel = "vanilladot")
# Load required Librbaries:
library(kernlab)
library(readr)
library(caret)
library(caTools)
library(e1071)
library(dplyr)
library(tidyr)
library(doParallel)
Model_linear <- ksvm(DIGIT~ ., data = train, scaled = FALSE, kernel = "vanilladot")
print(Model_linear)
Eval_linear<- predict(Model_linear, test)
#confusion matrix - Linear Kernel
confusionMatrix(Eval_linear,test$DIGIT)
#confusion matrix - Linear Kernel
confusionMatrix(Eval_linear,test$DIGIT)
library(e1071)
library(caret)
install.packages("reshape2")
library(caret)
#confusion matrix - Linear Kernel
confusionMatrix(Eval_linear,test$DIGIT)
#Using RBF Kernel
Model_RBF <- ksvm(DIGIT~ ., data = train, scaled = FALSE, kernel = "rbfdot")
Eval_RBF<- predict(Model_RBF,test)
#confusion matrix - RBF Kernel
confusionMatrix(Eval_RBF,test$DIGIT)
trainControl <- trainControl(method="cv", number=3)
# Metric <- "Accuracy" implies our Evaluation metric is Accuracy.
metric <- "Accuracy"
#Expand.grid functions takes set of hyperparameters, that we shall pass to our model.
set.seed(7)
grid <- expand.grid(.sigma=c(0.025, 0.05), .C=c(0.1,0.5,1) )
cl <- makePSOCKcluster(5)
registerDoParallel(cl)
fit.svm <- train(DIGIT~., data=train, method="svmRadial", metric=metric,tuneGrid=grid, trControl=trainControl)
stopCluster(cl)
print(fit.svm)
plot(fit.svm)
Eval_SVMRadial<- predict(fit.svm,test)
#confusion matrix - RBF Kernel
confusionMatrix(Eval_SVMRadial,test$DIGIT)
# Load required Librbaries:
library(kernlab)
library(readr)
library(caret)
library(caTools)
library(e1071)
library(dplyr)
library(tidyr)
library(doParallel)
train_data <- read_csv("mnist_train.csv", col_names = F)
test_data <- read_csv("mnist_test.csv", col_names = F)
renameColumns <- function(df){
colnames(df) <- paste0("Y", 0:(ncol(df)-1))
colnames(df)[which(names(df) == "Y0")] <- "DIGIT"
return(df)
}
train_data <- renameColumns(train_data)
colnames(train_data)
test_data <- renameColumns(test_data)
colnames(test_data)
# Changing output variable "DIGIT" to factor type
train_data$DIGIT <- as.factor(train_data$DIGIT)
test_data$DIGIT <- as.factor(test_data$DIGIT)
# Checking missing value
sum(sapply(train_data, function(x) sum(is.na(x)))) # No missing values
sum(sapply(test_data, function(x) sum(is.na(x)))) # No missing values
sum(duplicated(train_data)) # no duplicate rows
sum(duplicated(test_data)) # no duplicate rows
# Sampling the data to make the computation faster
set.seed(100)
train_subset.indices = sample(1:nrow(train_data), 0.15*nrow(train_data))
train = train_data[train_subset.indices, ]
test_subset.indices = sample(1:nrow(test_data), 0.15*nrow(test_data))
test <- test_data[test_subset.indices, ]
# Setup Parallel Processing
cl <- makePSOCKcluster(5)
registerDoParallel(cl)
?train
set.seed(3200)
trctrl <- trainControl(method = "cv", number = 3)
svm_Linear <- train(DIGIT ~., data = train, method = "svmLinear",trControl=trctrl,metric="Accuracy",tuneGrid=grid)
grid <- expand.grid(.sigma=c(0.025, 0.05), .C=c(0.1,0.5,1) )
svm_Linear <- train(DIGIT ~., data = train, method = "svmLinear",trControl=trctrl,metric="Accuracy",tuneGrid=grid)
svm_Linear <- train(DIGIT ~., data = train, method = "svmLinear",trControl=trctrl,metric="Accuracy")
print(svm_Linear)
plot(svm_Linear)
set.seed(3200)
trctrl <- trainControl(method = "cv", number = 3)
grid <- expand.grid(C = c(0, 0.1, 0.25, 0.5, 0.75, 1, 1.25))
svm_Linear <- train(DIGIT ~., data = train,
method = "svmLinear",trControl=trctrl,
metric="Accuracy",
preProcess = c("center", "scale"),
tuneLength = 10)
print(svm_Linear)
plot(svm_Linear)
set.seed(3200)
trainControl(method = "repeatedcv", number = 10, repeats = 3)
grid <- expand.grid(C = c(0, 0.1, 0.25, 0.5, 0.75, 1, 1.25))
svm_Linear <- train(DIGIT ~., data = train,
method = "svmLinear",trControl=trctrl,
metric="Accuracy",
preProcess = c("center", "scale"),
tuneLength = 10)
print(svm_Linear)
trainControl(method = "repeatedcv", number = 10, repeats = 3)
grid <- expand.grid(C = c(0, 0.1, 0.25, 0.5, 0.75, 1, 1.25))
svm_Linear <- train(DIGIT ~., data = train,
method = "svmLinear",trControl=trctrl,
metric="Accuracy",
tuneLength = 10)
print(svm_Linear)
trainControl(method = "repeatedcv", number = 10, repeats = 3)
grid <- expand.grid(C = c(0, 0.1, 0.25, 0.5, 0.75, 1, 1.25))
set.seed(3233)
svm_Linear <- train(DIGIT ~., data = train,
method = "svmLinear",trControl=trctrl,
metric="Accuracy",
tuneLength = 10)
print(svm_Linear)
trainControl(method = "repeatedcv", number = 10, repeats = 3)
grid <- expand.grid(C = c(0, 0.1, 0.25, 0.5, 0.75, 1, 1.25))
set.seed(3233)
svm_Linear <- train(DIGIT ~., data = train,
method = "svmLinear",trControl=trctrl,
tuneGrid = grid,
metric="Accuracy",
tuneLength = 10)
print(svm_Linear)
plot(svm_Linear)
Eval_linear<- predict(svm_Linear, test)
#confusion matrix - Linear Kernel
confusionMatrix(Eval_linear,test$DIGIT)
trainControl(method = "repeatedcv", number = 10, repeats = 3)
grid <- expand.grid(sigma = c(0.025, 0.05), C = c(0, 0.1, 0.25, 0.5, 0.75, 1, 1.25))
set.seed(3233)
svm_Radial<- train(DIGIT ~., data = train,
method = "svmRadial",trControl=trctrl,
tuneGrid = grid,
metric="Accuracy",
tuneLength = 10)
print(svm_Radial)
View(trctrl)
plot(fit.svm)
plot(svm_Radial)
# Using Hyperparameter Tuning and Cross Validation
trctrl <- trainControl(method = "cv", number = 3)
grid <- expand.grid(.sigma=c(0.025, 0.05), .C=c(0.1,0.5,1) )
set.seed(3233)
svm_Radial1<- train(DIGIT ~., data = train,
method = "svmRadial",trControl=trctrl,
tuneGrid = grid,
metric="Accuracy")
print(svm_Radial)
plot(fit.svm)
